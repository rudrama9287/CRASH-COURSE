{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78e13b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bf4a655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine you're trying to build a super-smart assistant using an AI language model (like ChatGPT).\n",
      "\n",
      "For simple questions, you just ask the AI, and it gives an answer. Easy!\n",
      "\n",
      "But what if the task is complex? Like:\n",
      "1.  \"Research the best dog breeds for apartment living.\"\n",
      "2.  \"Then, check their typical lifespan.\"\n",
      "3.  \"Then, find out if they are good with kids.\"\n",
      "4.  \"If all good, draft an email recommending one, *but if not*, go back and research another breed.\"\n",
      "5.  \"If the email is approved, send it.\"\n",
      "\n",
      "This isn't a single question; it's a **sequence of steps, decisions, and potentially repeating actions.**\n",
      "\n",
      "---\n",
      "\n",
      "**LangGraph, in simple words, is like building a \"Choose Your Own Adventure\" book for your AI.**\n",
      "\n",
      "Here's how:\n",
      "\n",
      "1.  **Pages (Nodes/Steps):** Each \"page\" in your book is a specific action. This could be:\n",
      "    *   Asking the AI a question.\n",
      "    *   Using a tool (like a web search, a calculator, or a calendar).\n",
      "    *   Saving some information.\n",
      "    *   Making a simple decision.\n",
      "\n",
      "2.  **Connections (Edges):** You draw lines between these pages, showing how the AI moves from one step to the next.\n",
      "\n",
      "3.  **Smart Decisions (Conditional Routing):** This is where the \"Choose Your Own Adventure\" magic happens. Instead of just going to the *next* page, you can say:\n",
      "    *   \"If the AI's answer was X, go to Page A.\"\n",
      "    *   \"If the AI's answer was Y, go to Page B.\"\n",
      "    *   \"If the tool found nothing, go to Page C.\"\n",
      "\n",
      "4.  **Repeating Steps (Loops):** Unlike a physical book where you just keep going forward, LangGraph lets your AI go back to previous pages. This is *super powerful* for things like:\n",
      "    *   **Self-correction:** \"Oops, that didn't work. Let's go back and try a different approach.\"\n",
      "    *   **Iterative tasks:** \"Keep researching until you find 3 suitable options.\"\n",
      "    *   **AI Agents:** This is how you build an AI that can plan, execute tools, observe the results, and then decide what to do next, potentially trying again if it fails.\n",
      "\n",
      "5.  **Memory (State):** Throughout this whole \"adventure,\" LangGraph remembers everything that happened. So, the AI doesn't forget important details from earlier pages as it navigates through your complex process.\n",
      "\n",
      "---\n",
      "\n",
      "**In a nutshell:**\n",
      "\n",
      "LangGraph lets you design **complex, multi-step workflows** for your AI, where the AI can make decisions, use tools, loop back, and correct itself, all while remembering the context. It turns simple AI prompts into sophisticated, adaptive systems capable of handling real-world, multi-part problems.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = genai.Client(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")\n",
    "\n",
    "res = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"Explain LangGraph in simple words\"\n",
    ")\n",
    "\n",
    "print(res.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c38978d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm doing well, thank you for asking. I'm ready to help you with whatever you need.\n",
      "\n",
      "How are you today?\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = genai.Client(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"Hello, how are you?\"\n",
    ")\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7057c6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponse(\n",
       "  automatic_function_calling_history=[],\n",
       "  candidates=[\n",
       "    Candidate(\n",
       "      content=Content(\n",
       "        parts=[\n",
       "          Part(\n",
       "            text=\"\"\"Hello! I'm doing well, thank you for asking. I'm ready to help you with whatever you need.\n",
       "\n",
       "How are you today?\"\"\"\n",
       "          ),\n",
       "        ],\n",
       "        role='model'\n",
       "      ),\n",
       "      finish_reason=<FinishReason.STOP: 'STOP'>,\n",
       "      index=0\n",
       "    ),\n",
       "  ],\n",
       "  model_version='gemini-2.5-flash',\n",
       "  response_id='cweOaZ_YMZjijuMP5tTu6QU',\n",
       "  sdk_http_response=HttpResponse(\n",
       "    headers=<dict len=11>\n",
       "  ),\n",
       "  usage_metadata=GenerateContentResponseUsageMetadata(\n",
       "    candidates_token_count=31,\n",
       "    prompt_token_count=7,\n",
       "    prompt_tokens_details=[\n",
       "      ModalityTokenCount(\n",
       "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "        token_count=7\n",
       "      ),\n",
       "    ],\n",
       "    thoughts_token_count=110,\n",
       "    total_token_count=148\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0d2c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(\n",
    "    top_k_results=5,\n",
    "    doc_content_chars_max=500\n",
    ")\n",
    "\n",
    "wiki_tool = WikipediaQueryRun(\n",
    "    api_wrapper=api_wrapper\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d94eae56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Generative artificial intelligence\\nSummary: Generative artificial intelligence, also known as generative AI or GenAI, is a subfield of artificial intelligence that uses generative models to generate text, images, videos, audio, software code or other forms of data.\\nThese models learn the underlying patterns and structures of their training data and use them to generate new data\\nin response to input, which often takes the form of natural language prompts.\\nThe generated material is often cal'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_tool.run({\"query\":\"Generative AI\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6864563b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'LangGraph — Architecture and Design | by Shuvrajyoti Debroy', 'url': 'https://medium.com/@shuv.sdr/langgraph-architecture-and-design-280c365aaf2c', 'content': 'LangGraph is an advanced framework designed for building stateful, multiagent applications.\\n Nodes are functions that do the actual computation. Edges define how the execution flows from one step to the next. State is a shared memory that remembers everything across nodes.\\n LangGraph’s unique capabilities include looping and branching for making dynamic decisions, state persistence to maintain context over long interactions, human-in-the-loop functionality for timely human interventions, and time travel to facilitate convenient debugging.\\n LangGraph offers state management, allowing the workflow to maintain and modify context across different nodes. It also offers conditional transitions, enabling the workflow to make decisions at runtime and branch accordingly.', 'score': 0.99998593}, {'title': 'LangGraph overview', 'url': 'https://docs.langchain.com/oss/python/langgraph/overview', 'content': '## \\u200b Core benefits\\n\\nLangGraph provides low-level supporting infrastructure for any long-running, stateful workflow or agent. LangGraph does not abstract prompts or architecture, and provides the following central benefits: [...] architectures for common LLM and tool-calling loops. LangGraph is focused on the underlying capabilities important for agent orchestration: durable execution, streaming, human-in-the-loop, and more. [...] Trusted by companies shaping the future of agents— including Klarna, Replit, Elastic, and more— LangGraph is a low-level orchestration framework and runtime for building, managing, and deploying long-running, stateful agents. LangGraph is very low-level, and focused entirely on agent orchestration. Before using LangGraph, we recommend you familiarize yourself with some of the components used to build agents, starting with models and tools. We will commonly use LangChain components throughout the documentation to integrate models and tools, but you don’t need to use LangChain to use LangGraph. If you are just getting started with agents or want a higher-level abstraction, we recommend you use LangChain’s agents that provide pre-built architectures for common LLM and tool-calling loops.', 'score': 0.99997663}, {'title': 'What is LangGraph?', 'url': 'https://www.ibm.com/think/topics/langgraph', 'content': '# What is LangGraph?\\n\\n## Authors\\n\\nBryan Clark \\n\\nSenior Technology Advocate\\n\\n## LangGraph overview\\n\\nLangGraph, created by LangChain, is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. It provides a set of tools and libraries that enable users to create, run and optimize large language models (LLMs) in a scalable and efficient manner. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. [...] LangGraph is also built on several key technologies, including LangChain, a Python framework for building AI applications. LangChain includes a library for building and managing LLMs. LangGraph also uses the human-in-the-loop approach. By combining these technologies with a set of APIs and tools, LangGraph provides users with a versatile platform for developing AI solutions and workflows including chatbots, state graphs and other agent-based systems.\\n\\nDelve deeper into the world of LangGraph by exploring its key features, benefits and use cases. By the end of this article, you will have the knowledge and resources to take the next steps with LangGraph.\\n\\n## Key components of LangGraph [...] LangGraph workflow\\n\\nLangGraph illuminates the processes within an AI workflow, allowing full transparency of the agent’s state. Within LangGraph, the “state” feature serves as a memory bank that records and tracks all the valuable information processed by the AI system. It’s similar to a digital notebook where the system captures and updates data as it moves through various stages of a workflow or graph analysis.', 'score': 0.9999707}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tool = TavilySearchResults(\n",
    "    max_results=3,\n",
    "    tavily_api_key=os.getenv(\"TAVILY_API_KEY\")\n",
    ")\n",
    "\n",
    "print(tool.run(\"LangGraph explained\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a354ee31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'What is Generative AI? | IBM',\n",
       "  'url': 'https://www.ibm.com/think/topics/generative-ai',\n",
       "  'content': \"# What is generative AI?\\n\\n## Authors\\n\\nCole Stryker \\n\\nStaff Editor, AI Models\\n\\nIBM Think\\n\\nMark Scapicchio \\n\\nEditor, Topics & Insights\\n\\nIBM Think\\n\\n## What is generative AI?\\n\\nGenerative AI, sometimes called gen AI, is artificial intelligence (AI) that can create original content such as text, images, video, audio or software code in response to a user’s prompt or request.\\n\\nGenerative AI relies on sophisticated machine learning models called deep learning modelsalgorithms that simulate the learning and decision-making processes of the human brain. These models work by identifying and encoding the patterns and relationships in huge amounts of data, and then using that information to understand users' natural language requests or questions and respond with relevant new content. [...] Generative AI begins with a foundation model, a deep learning model that serves as the basis for multiple different types of generative AI applications. The most common foundation models today are large language models (LLMs), created for text generation applications, but there are also foundation models for image generation, video generation, and sound and music generation as well as multimodal foundation models that can support several kinds content generation. [...] Science, engineering and research  \\n\\nGenerative AI models can help scientists and engineers propose novel solutions to complex problems. In healthcare, for example, generative models can be applied to synthesize medical images for training and testing medical imaging systems.\\n\\n## Generative AI, AI agents and agentic AI\\n\\nAn AI agent is an autonomous AI program—it can perform tasks and accomplish goals on behalf of a user or another system without human intervention, by designing its own workflow and using available tools (other applications or services). Agentic AI is a system of multiple AI agents, the efforts of which are coordinated, or orchestrated, to accomplish a more complex task or a greater goal than any single agent in the system could accomplish.\",\n",
       "  'score': 0.9466806},\n",
       " {'title': 'What is generative AI? - IBM Research',\n",
       "  'url': 'https://research.ibm.com/blog/what-is-generative-AI',\n",
       "  'content': '9 minute read\\n\\n# What is generative AI?\\n\\nGenerative AI refers to deep-learning models that can generate high-quality text, images, and other content based on the data they were trained on.\\n\\nArtificial intelligence has gone through many cycles of hype, but even to skeptics, the release of ChatGPT seems to mark a turning point. OpenAI’s chatbot, powered by its latest large language model, can write poems, tell jokes, and churn out essays that look like a human created them. Prompt ChatGPT with a few words, and out comes love poems in the form of Yelp reviews, or song lyrics in the style of Nick Cave. [...] ## The rise of deep generative models\\n\\nGenerative AI refers to deep-learning models that can take raw data — say, all of Wikipedia or the collected works of Rembrandt — and “learn” to generate statistically probable outputs when prompted. At a high level, generative models encode a simplified representation of their training data and draw from it to create a new work that’s similar, but not identical, to the original data. [...] Generative AI holds enormous potential to create new capabilities and value for enterprise. However, it also can introduce new risks, be they legal, financial or reputational. Many generative models, including those powering ChatGPT, can spout information that sounds authoritative but isn’t true (sometimes called “hallucinations”) or is objectionable and biased. Generative models can also inadvertently ingest information that’s personal or copyrighted in their training data and output it later, creating unique challenges for privacy and intellectual property laws. Solving these issues is an open area of research, and something we covered in our next blog post.\\n\\n### Learn more about the future of AI',\n",
       "  'score': 0.9451216},\n",
       " {'title': 'How Does Generative AI Work | Microsoft AI',\n",
       "  'url': 'https://www.microsoft.com/en-us/ai/ai-101/how-does-generative-ai-work',\n",
       "  'content': 'Generative AI refers to a class of AI systems that are designed to create new content, such as text, images, music, or videos, by learning patterns from existing data. These models, like the GPT series and DALL-E, use techniques such as deep learning to produce outputs that can mimic human creativity and expression. Learn more.\\n Controlling the output of generative AI systems prevents the dissemination of potentially false or harmful information. It also helps promote fairness and inclusivity by mitigating risks related to biases. [...] The key feature of generative AI is its ability to generate new content that feels natural, contextually relevant, and often indistinguishable from human-generated content. As a result, generative AI helps organizations save time, streamline processes, and boost creativity.\\n Generative AI uses deep learning algorithms, such as neural networks, to analyze patterns from large datasets. It then predicts and constructs outputs that align with the data it has been trained on, in turn creating novel combinations and variations in the form of new content.\\n Generative AI is a subset of AI. AI encompasses a broader range of technologies and applications, including tasks like data analysis, classification, and decision-making, which may not involve content generation. Learn more. [...] Generative AI is built upon the foundation of neural networks, which are computational models inspired by the structure and function of the human brain. These networks consist of multiple layers of interconnected neurons that process and transmit information, where each layer serves a specific purpose in processing information.  \\n   \\n The first layer, the input layer, receives raw data that gets transformed the more it travels from layer to layer, ultimately producing output in the final layer. This hierarchical structure allows neural networks to learn complex patterns and representations in data, with deeper layers often identifying more abstract patterns—just like how the human brain processes sensory information.',\n",
       "  'score': 0.939919}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.invoke({\"query\":\"what is Generative AI\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bec67fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import YouTubeSearchTool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "459221bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool=YouTubeSearchTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f7ec92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'youtube_search'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c830a4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search for youtube videos associated with a person. the input to this tool should be a comma separated list, the first part contains a person name and the second a number that is the maximum number of video results to return aka num_results. the second part is optional'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c300f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['https://www.youtube.com/watch?v=fQw1_U22URk&pp=ygULa3Jpc2ggbmF5YWs%3D', 'https://www.youtube.com/watch?v=rZ_bRHWgYHU&pp=ygULa3Jpc2ggbmF5YWs%3D']\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.run(\"krish nayak\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2539acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a:int,b:int) ->int:\n",
    "    return a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5c5937c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply(10,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f05efa29",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'invoke'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmultiply\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m(\u001b[32m10\u001b[39m,\u001b[32m20\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'function' object has no attribute 'invoke'"
     ]
    }
   ],
   "source": [
    "multiply.invoke(10,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "437c651a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'invoke'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmultiply\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m({\u001b[33m\"\u001b[39m\u001b[33ma\u001b[39m\u001b[33m\"\u001b[39m:\u001b[32m10\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m:\u001b[32m20\u001b[39m})\n",
      "\u001b[31mAttributeError\u001b[39m: 'function' object has no attribute 'invoke'"
     ]
    }
   ],
   "source": [
    "multiply.invoke({\"a\":10,\"b\":20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "613c5631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f97c24f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a:int,b:int) ->int:\n",
    "    \"\"\"this is a tool for the multiplication\"\"\"\n",
    "    return a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1356ac9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.invoke({\"a\":10,\"b\":20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0065abc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a tool for the multiplication'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b315db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': {'title': 'A', 'type': 'integer'},\n",
       " 'b': {'title': 'B', 'type': 'integer'}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57094895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
